{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3b0119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af90b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\pragy\\cloud_architecture\\neural_symbolic\\data\\train_data.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\pragy\\cloud_architecture\\neural_symbolic\\data\\test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cf88d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "078fe0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_id', 'student_id', 'assignment_id', 'problem_id', 'start_time',\n",
       "       'time_on_task', 'answer_before_tutoring', 'fraction_of_hints_used',\n",
       "       'attempt_count', 'answer_given', 'problem_completed', 'correct',\n",
       "       'next_correct', 'content_source', 'skills', 'problem_type',\n",
       "       'tutoring_types', 'student_answer_count', 'mean_correct',\n",
       "       'mean_time_on_task', 'class_id', 'account_creation_date',\n",
       "       'started_problem_sets_count', 'completed_problem_sets_count',\n",
       "       'started_skill_builders_count', 'mastered_skill_builders_count',\n",
       "       'answered_problems_count', 'mean_problem_correctness',\n",
       "       'mean_problem_time_on_task', 'mean_class_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22a3205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_id', 'student_id', 'assignment_id', 'problem_id', 'start_time',\n",
       "       'time_on_task', 'answer_before_tutoring', 'fraction_of_hints_used',\n",
       "       'attempt_count', 'answer_given', 'problem_completed', 'correct',\n",
       "       'content_source', 'skills', 'problem_type', 'tutoring_types',\n",
       "       'student_answer_count', 'mean_correct', 'mean_time_on_task', 'class_id',\n",
       "       'account_creation_date', 'started_problem_sets_count',\n",
       "       'completed_problem_sets_count', 'started_skill_builders_count',\n",
       "       'mastered_skill_builders_count', 'answered_problems_count',\n",
       "       'mean_problem_correctness', 'mean_problem_time_on_task',\n",
       "       'mean_class_score', 'next_correct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'next_correct'\n",
    "def function(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    cols = [c for c in df.columns if c!=col] + [col]\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "train_data = function(train_data,col)\n",
    "test_data = function(test_data,col)\n",
    "\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b93b6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>time_on_task</th>\n",
       "      <th>answer_before_tutoring</th>\n",
       "      <th>fraction_of_hints_used</th>\n",
       "      <th>attempt_count</th>\n",
       "      <th>answer_given</th>\n",
       "      <th>...</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>started_problem_sets_count</th>\n",
       "      <th>completed_problem_sets_count</th>\n",
       "      <th>started_skill_builders_count</th>\n",
       "      <th>mastered_skill_builders_count</th>\n",
       "      <th>answered_problems_count</th>\n",
       "      <th>mean_problem_correctness</th>\n",
       "      <th>mean_problem_time_on_task</th>\n",
       "      <th>mean_class_score</th>\n",
       "      <th>next_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16475574</td>\n",
       "      <td>2259</td>\n",
       "      <td>1426268</td>\n",
       "      <td>1694676</td>\n",
       "      <td>2021-05-18 17:03:26.559000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16654914</td>\n",
       "      <td>2259</td>\n",
       "      <td>1443864</td>\n",
       "      <td>1631611</td>\n",
       "      <td>2021-05-28 17:09:41.198000+00:00</td>\n",
       "      <td>60.625</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16654914</td>\n",
       "      <td>2259</td>\n",
       "      <td>1443864</td>\n",
       "      <td>1631613</td>\n",
       "      <td>2021-05-28 17:12:38.346000+00:00</td>\n",
       "      <td>44.138</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16711054</td>\n",
       "      <td>2259</td>\n",
       "      <td>1445768</td>\n",
       "      <td>1632407</td>\n",
       "      <td>2021-06-04 17:25:57.552000+00:00</td>\n",
       "      <td>75.820</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16711054</td>\n",
       "      <td>2259</td>\n",
       "      <td>1445768</td>\n",
       "      <td>1632408</td>\n",
       "      <td>2021-06-04 17:27:14.550000+00:00</td>\n",
       "      <td>18.387</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16711054</td>\n",
       "      <td>2259</td>\n",
       "      <td>1445768</td>\n",
       "      <td>1632430</td>\n",
       "      <td>2021-06-04 17:27:41.921000+00:00</td>\n",
       "      <td>45.407</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-27 20:47:08.261000-05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.24470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762888</td>\n",
       "      <td>2021-05-19 12:24:11.169000+00:00</td>\n",
       "      <td>11.377</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762889</td>\n",
       "      <td>2021-05-19 12:24:23.215000+00:00</td>\n",
       "      <td>5.911</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762890</td>\n",
       "      <td>2021-05-19 12:24:30.011000+00:00</td>\n",
       "      <td>6.844</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762891</td>\n",
       "      <td>2021-05-19 12:24:37.861000+00:00</td>\n",
       "      <td>7.862</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762892</td>\n",
       "      <td>2021-05-19 12:24:46.641000+00:00</td>\n",
       "      <td>7.900</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16492425</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426307</td>\n",
       "      <td>1762893</td>\n",
       "      <td>2021-05-19 12:24:55.357000+00:00</td>\n",
       "      <td>7.058</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763338</td>\n",
       "      <td>2021-05-19 12:25:19.784000+00:00</td>\n",
       "      <td>76.353</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763339</td>\n",
       "      <td>2021-05-19 12:26:36.861000+00:00</td>\n",
       "      <td>4.220</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763340</td>\n",
       "      <td>2021-05-19 12:26:42.930000+00:00</td>\n",
       "      <td>6.423</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763341</td>\n",
       "      <td>2021-05-19 12:26:50.242000+00:00</td>\n",
       "      <td>5.114</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763342</td>\n",
       "      <td>2021-05-19 12:26:56.371000+00:00</td>\n",
       "      <td>20.126</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763343</td>\n",
       "      <td>2021-05-19 12:27:17.335000+00:00</td>\n",
       "      <td>6.041</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763344</td>\n",
       "      <td>2021-05-19 12:27:24.589000+00:00</td>\n",
       "      <td>12.831</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16492456</td>\n",
       "      <td>2358</td>\n",
       "      <td>1426311</td>\n",
       "      <td>1763345</td>\n",
       "      <td>2021-05-19 12:27:38.615000+00:00</td>\n",
       "      <td>8.315</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-01-28 10:35:46.830000-05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.96019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_id  student_id  assignment_id  problem_id  \\\n",
       "0   16475574        2259        1426268     1694676   \n",
       "1   16654914        2259        1443864     1631611   \n",
       "2   16654914        2259        1443864     1631613   \n",
       "3   16711054        2259        1445768     1632407   \n",
       "4   16711054        2259        1445768     1632408   \n",
       "5   16711054        2259        1445768     1632430   \n",
       "6   16492425        2358        1426307     1762888   \n",
       "7   16492425        2358        1426307     1762889   \n",
       "8   16492425        2358        1426307     1762890   \n",
       "9   16492425        2358        1426307     1762891   \n",
       "10  16492425        2358        1426307     1762892   \n",
       "11  16492425        2358        1426307     1762893   \n",
       "12  16492456        2358        1426311     1763338   \n",
       "13  16492456        2358        1426311     1763339   \n",
       "14  16492456        2358        1426311     1763340   \n",
       "15  16492456        2358        1426311     1763341   \n",
       "16  16492456        2358        1426311     1763342   \n",
       "17  16492456        2358        1426311     1763343   \n",
       "18  16492456        2358        1426311     1763344   \n",
       "19  16492456        2358        1426311     1763345   \n",
       "\n",
       "                          start_time  time_on_task answer_before_tutoring  \\\n",
       "0   2021-05-18 17:03:26.559000+00:00           NaN                    NaN   \n",
       "1   2021-05-28 17:09:41.198000+00:00        60.625                   True   \n",
       "2   2021-05-28 17:12:38.346000+00:00        44.138                   True   \n",
       "3   2021-06-04 17:25:57.552000+00:00        75.820                   True   \n",
       "4   2021-06-04 17:27:14.550000+00:00        18.387                   True   \n",
       "5   2021-06-04 17:27:41.921000+00:00        45.407                   True   \n",
       "6   2021-05-19 12:24:11.169000+00:00        11.377                  False   \n",
       "7   2021-05-19 12:24:23.215000+00:00         5.911                  False   \n",
       "8   2021-05-19 12:24:30.011000+00:00         6.844                  False   \n",
       "9   2021-05-19 12:24:37.861000+00:00         7.862                  False   \n",
       "10  2021-05-19 12:24:46.641000+00:00         7.900                  False   \n",
       "11  2021-05-19 12:24:55.357000+00:00         7.058                  False   \n",
       "12  2021-05-19 12:25:19.784000+00:00        76.353                  False   \n",
       "13  2021-05-19 12:26:36.861000+00:00         4.220                  False   \n",
       "14  2021-05-19 12:26:42.930000+00:00         6.423                  False   \n",
       "15  2021-05-19 12:26:50.242000+00:00         5.114                   True   \n",
       "16  2021-05-19 12:26:56.371000+00:00        20.126                  False   \n",
       "17  2021-05-19 12:27:17.335000+00:00         6.041                  False   \n",
       "18  2021-05-19 12:27:24.589000+00:00        12.831                  False   \n",
       "19  2021-05-19 12:27:38.615000+00:00         8.315                  False   \n",
       "\n",
       "    fraction_of_hints_used  attempt_count  answer_given  ...  \\\n",
       "0                      NaN              0         False  ...   \n",
       "1                      NaN              1         False  ...   \n",
       "2                      NaN              1         False  ...   \n",
       "3                      NaN              2          True  ...   \n",
       "4                      NaN              2          True  ...   \n",
       "5                      NaN              1         False  ...   \n",
       "6                      NaN              1          True  ...   \n",
       "7                      NaN              1          True  ...   \n",
       "8                      NaN              1          True  ...   \n",
       "9                      NaN              1          True  ...   \n",
       "10                     NaN              1          True  ...   \n",
       "11                     NaN              1          True  ...   \n",
       "12                     NaN              1          True  ...   \n",
       "13                     NaN              1          True  ...   \n",
       "14                     NaN              1          True  ...   \n",
       "15                     NaN              1         False  ...   \n",
       "16                     NaN              1          True  ...   \n",
       "17                     NaN              1          True  ...   \n",
       "18                     NaN              1          True  ...   \n",
       "19                     NaN              1          True  ...   \n",
       "\n",
       "               account_creation_date started_problem_sets_count  \\\n",
       "0   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "1   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "2   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "3   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "4   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "5   2019-01-27 20:47:08.261000-05:00                          3   \n",
       "6   2019-01-28 10:35:46.830000-05:00                          4   \n",
       "7   2019-01-28 10:35:46.830000-05:00                          4   \n",
       "8   2019-01-28 10:35:46.830000-05:00                          4   \n",
       "9   2019-01-28 10:35:46.830000-05:00                          4   \n",
       "10  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "11  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "12  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "13  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "14  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "15  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "16  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "17  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "18  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "19  2019-01-28 10:35:46.830000-05:00                          4   \n",
       "\n",
       "   completed_problem_sets_count started_skill_builders_count  \\\n",
       "0                             2                            0   \n",
       "1                             2                            0   \n",
       "2                             2                            0   \n",
       "3                             2                            0   \n",
       "4                             2                            0   \n",
       "5                             2                            0   \n",
       "6                             4                            0   \n",
       "7                             4                            0   \n",
       "8                             4                            0   \n",
       "9                             4                            0   \n",
       "10                            4                            0   \n",
       "11                            4                            0   \n",
       "12                            4                            0   \n",
       "13                            4                            0   \n",
       "14                            4                            0   \n",
       "15                            4                            0   \n",
       "16                            4                            0   \n",
       "17                            4                            0   \n",
       "18                            4                            0   \n",
       "19                            4                            0   \n",
       "\n",
       "   mastered_skill_builders_count answered_problems_count  \\\n",
       "0                              0                      10   \n",
       "1                              0                      10   \n",
       "2                              0                      10   \n",
       "3                              0                      10   \n",
       "4                              0                      10   \n",
       "5                              0                      10   \n",
       "6                              0                      21   \n",
       "7                              0                      21   \n",
       "8                              0                      21   \n",
       "9                              0                      21   \n",
       "10                             0                      21   \n",
       "11                             0                      21   \n",
       "12                             0                      21   \n",
       "13                             0                      21   \n",
       "14                             0                      21   \n",
       "15                             0                      21   \n",
       "16                             0                      21   \n",
       "17                             0                      21   \n",
       "18                             0                      21   \n",
       "19                             0                      21   \n",
       "\n",
       "    mean_problem_correctness  mean_problem_time_on_task  mean_class_score  \\\n",
       "0                   0.333333                   45.24470               0.5   \n",
       "1                   0.333333                   45.24470               0.5   \n",
       "2                   0.333333                   45.24470               0.5   \n",
       "3                   0.333333                   45.24470               0.5   \n",
       "4                   0.333333                   45.24470               0.5   \n",
       "5                   0.333333                   45.24470               0.5   \n",
       "6                   0.100000                   28.96019               0.0   \n",
       "7                   0.100000                   28.96019               0.0   \n",
       "8                   0.100000                   28.96019               0.0   \n",
       "9                   0.100000                   28.96019               0.0   \n",
       "10                  0.100000                   28.96019               0.0   \n",
       "11                  0.100000                   28.96019               0.0   \n",
       "12                  0.100000                   28.96019               0.0   \n",
       "13                  0.100000                   28.96019               0.0   \n",
       "14                  0.100000                   28.96019               0.0   \n",
       "15                  0.100000                   28.96019               0.0   \n",
       "16                  0.100000                   28.96019               0.0   \n",
       "17                  0.100000                   28.96019               0.0   \n",
       "18                  0.100000                   28.96019               0.0   \n",
       "19                  0.100000                   28.96019               0.0   \n",
       "\n",
       "    next_correct  \n",
       "0           True  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "5           True  \n",
       "6          False  \n",
       "7          False  \n",
       "8          False  \n",
       "9          False  \n",
       "10         False  \n",
       "11         False  \n",
       "12         False  \n",
       "13         False  \n",
       "14          True  \n",
       "15         False  \n",
       "16         False  \n",
       "17         False  \n",
       "18         False  \n",
       "19         False  \n",
       "\n",
       "[20 rows x 30 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88b62ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\pragy\\anaconda3\\envs\\main\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.10.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.9.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.0->aiohttp->torch-geometric) (3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2025.4.26)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pragy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "767df506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (110474, 30)\n",
      "Column names:  ['log_id', 'student_id', 'assignment_id', 'problem_id', 'start_time', 'time_on_task', 'answer_before_tutoring', 'fraction_of_hints_used', 'attempt_count', 'answer_given', 'problem_completed', 'correct', 'content_source', 'skills', 'problem_type', 'tutoring_types', 'student_answer_count', 'mean_correct', 'mean_time_on_task', 'class_id', 'account_creation_date', 'started_problem_sets_count', 'completed_problem_sets_count', 'started_skill_builders_count', 'mastered_skill_builders_count', 'answered_problems_count', 'mean_problem_correctness', 'mean_problem_time_on_task', 'mean_class_score', 'next_correct']\n",
      "Unique students:  10000\n",
      "Unique problems:  21777\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape: \",train_data.shape)\n",
    "print(\"Column names: \", train_data.columns.tolist())\n",
    "print(\"Unique students: \",train_data['student_id'].nunique())\n",
    "print(\"Unique problems: \",train_data['problem_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a718cd5",
   "metadata": {},
   "source": [
    "### Node types are of three\n",
    "1. Student nodes = 10000 students\n",
    "2. Problem nodes = 21777 problems \n",
    "3. Skill nodes = length of all_skills\n",
    "\n",
    "### Edge types are of two\n",
    "1. student-problem edges \n",
    "2. problem-skill edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8899496",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12f4549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_graph_structure(df):\n",
    "    \"\"\"\n",
    "    Analyze the data structure and extract unique skills\n",
    "    \"\"\"\n",
    "    all_skills = set()\n",
    "    for skills_str in df['skills'].dropna():\n",
    "        if isinstance(skills_str, str):\n",
    "            skills = [s.strip() for s in skills_str.split(',')]\n",
    "            all_skills.update(skills)\n",
    "    \n",
    "    print(\"=== GRAPH STRUCTURE ANALYSIS ===\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Unique students: {df['student_id'].nunique()}\")\n",
    "    print(f\"Unique problems: {df['problem_id'].nunique()}\")\n",
    "    print(f\"Unique skills: {len(all_skills)}\")\n",
    "    \n",
    "    attempts_per_student = df.groupby('student_id').size()\n",
    "    print(f\"\\nStudent attempt distribution:\")\n",
    "    print(f\"Min attempts: {attempts_per_student.min()}\")\n",
    "    print(f\"Max attempts: {attempts_per_student.max()}\")\n",
    "    print(f\"Mean attempts: {attempts_per_student.mean():.2f}\")\n",
    "    print(f\"Median attempts: {attempts_per_student.median():.2f}\")\n",
    "    \n",
    "    return list(all_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "945cc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_mappings(df, unique_skills):\n",
    "    \"\"\"\n",
    "    Create mappings from IDs to node indices\n",
    "    \"\"\"\n",
    "    # Student ID to index mapping\n",
    "    unique_students = df['student_id'].unique()\n",
    "    student_to_idx = {student_id: idx for idx, student_id in enumerate(unique_students)}\n",
    "    \n",
    "    # Problem ID to index mapping\n",
    "    unique_problems = df['problem_id'].unique()\n",
    "    problem_to_idx = {problem_id: idx for idx, problem_id in enumerate(unique_problems)}\n",
    "    \n",
    "    # Skill to index mapping\n",
    "    skill_to_idx = {skill: idx for idx, skill in enumerate(unique_skills)}\n",
    "    \n",
    "    print(\"=== NODE MAPPINGS CREATED ===\")\n",
    "    print(f\"Students: {len(student_to_idx)} mappings\")\n",
    "    print(f\"Problems: {len(problem_to_idx)} mappings\")\n",
    "    print(f\"Skills: {len(skill_to_idx)} mappings\")\n",
    "    \n",
    "    return student_to_idx, problem_to_idx, skill_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7f5969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adaptive_temporal_sequences(df, base_sequence_length=5, max_sequences_per_student=3, device='cuda'):\n",
    "    \"\"\"\n",
    "    Create adaptive sequences that handle variable student attempt counts\n",
    "    Each student gets multiple sequences of different lengths based on their attempt history\n",
    "    \"\"\"\n",
    "    print(\"=== CREATING ADAPTIVE TEMPORAL SEQUENCES ===\")\n",
    "    \n",
    "    # Sort by student and time\n",
    "    df_sorted = df.sort_values(['student_id', 'start_time']).reset_index(drop=True)\n",
    "    \n",
    "    sequences = []\n",
    "    student_stats = {\n",
    "        'total_students': 0,\n",
    "        'students_with_sequences': 0,\n",
    "        'sequence_lengths': [],\n",
    "        'students_by_attempts': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    for student_id in df_sorted['student_id'].unique():\n",
    "        student_data = df_sorted[df_sorted['student_id'] == student_id]\n",
    "        num_attempts = len(student_data)\n",
    "        \n",
    "        student_stats['total_students'] += 1\n",
    "        student_stats['students_by_attempts'][num_attempts] += 1\n",
    "        \n",
    "        # Only create sequences if student has enough attempts\n",
    "        if num_attempts >= base_sequence_length + 1:\n",
    "            student_stats['students_with_sequences'] += 1\n",
    "            \n",
    "            # Determine sequence lengths to create for this student\n",
    "            max_possible_length = num_attempts - 1  # Need 1 for prediction\n",
    "            \n",
    "            if max_sequences_per_student == 1:\n",
    "                # Single sequence with maximum available history\n",
    "                sequence_lengths = [min(max_possible_length, base_sequence_length * 2)]\n",
    "            else:\n",
    "                # Multiple sequences with different lengths\n",
    "                if max_possible_length <= base_sequence_length:\n",
    "                    sequence_lengths = [max_possible_length]\n",
    "                else:\n",
    "                    # Create sequences of varying lengths\n",
    "                    step = max(1, (max_possible_length - base_sequence_length) // (max_sequences_per_student - 1))\n",
    "                    sequence_lengths = list(range(base_sequence_length, max_possible_length + 1, step))\n",
    "                    sequence_lengths = sequence_lengths[:max_sequences_per_student]\n",
    "                    \n",
    "                    # Always include the maximum length\n",
    "                    if max_possible_length not in sequence_lengths:\n",
    "                        sequence_lengths[-1] = max_possible_length\n",
    "            \n",
    "            # Create sequences for this student\n",
    "            for seq_len in sequence_lengths:\n",
    "                # Use most recent seq_len attempts as history\n",
    "                sequence = student_data.iloc[-seq_len-1:-1].copy()  # Last seq_len attempts (excluding target)\n",
    "                target = student_data.iloc[-1]['next_correct']  # Last attempt as target\n",
    "                \n",
    "                sequences.append({\n",
    "                    'sequence_id': len(sequences),\n",
    "                    'student_id': student_id,\n",
    "                    'sequence_length': seq_len,\n",
    "                    'sequence_data': sequence,\n",
    "                    'target': target,\n",
    "                    'prediction_problem_id': student_data.iloc[-1]['problem_id']\n",
    "                })\n",
    "                \n",
    "                student_stats['sequence_lengths'].append(seq_len)\n",
    "    \n",
    "    print(f\"\\n=== SEQUENCE CREATION SUMMARY ===\")\n",
    "    print(f\"Total students: {student_stats['total_students']}\")\n",
    "    print(f\"Students with sequences: {student_stats['students_with_sequences']}\")\n",
    "    print(f\"Total sequences created: {len(sequences)}\")\n",
    "    print(f\"Average sequences per valid student: {len(sequences) / student_stats['students_with_sequences']:.2f}\")\n",
    "    print(f\"Sequence length range: {min(student_stats['sequence_lengths'])}-{max(student_stats['sequence_lengths'])}\")\n",
    "    \n",
    "    return sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d550f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_node_features(sequences, df, student_to_idx, problem_to_idx, skill_to_idx, device='cuda'):\n",
    "    \"\"\"\n",
    "    Extract node features that capture temporal learning patterns for variable sequences\n",
    "    \"\"\"\n",
    "    print(\"=== EXTRACTING TEMPORAL NODE FEATURES ===\")\n",
    "    \n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        print(\"CUDA not available, falling back to CPU\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # === SEQUENCE-BASED STUDENT FEATURES (Dynamic) ===\n",
    "    sequence_student_features = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        sequence_data = seq['sequence_data']\n",
    "        seq_len = seq['sequence_length']\n",
    "        student_id = seq['student_id']\n",
    "        \n",
    "        # Get additional student info from original data\n",
    "        student_info = df[df['student_id'] == student_id].iloc[0]\n",
    "        \n",
    "        # Skill diversity and mastery\n",
    "        unique_skills = set()\n",
    "        for skills_str in sequence_data['skills'].dropna():\n",
    "            if isinstance(skills_str, str):\n",
    "                unique_skills.update([s.strip() for s in skills_str.split(',')])\n",
    "        \n",
    "        # Calculate temporal features from the sequence\n",
    "        features = [\n",
    "            # Static student features\n",
    "            float(student_info['class_id']) if pd.notna(student_info['class_id']) else 0.0,\n",
    "            float(seq_len),  # Sequence length as feature\n",
    "            \n",
    "            # Performance metrics within sequence\n",
    "            float(sequence_data['correct'].mean()),  # Average correctness\n",
    "            float(sequence_data['time_on_task'].mean()),  # Average time\n",
    "            float(sequence_data['fraction_of_hints_used'].mean()),  # Average hint usage\n",
    "            \n",
    "            # Learning progression indicators\n",
    "            float(sequence_data['correct'].sum()),  # Total correct in sequence\n",
    "            float(sequence_data['correct'].iloc[-1] - sequence_data['correct'].iloc[0]) if len(sequence_data) > 1 else 0.0,  # Recent improvement\n",
    "            \n",
    "            # Skill diversity\n",
    "            float(len(unique_skills)),  # Number of different skills attempted\n",
    "            \n",
    "            # Content source diversity\n",
    "            float(sequence_data['content_source'].nunique()),\n",
    "            \n",
    "            # Performance consistency\n",
    "            float(sequence_data['correct'].std()) if len(sequence_data) > 1 else 0.0,  # Variability\n",
    "            \n",
    "            # Additional temporal features\n",
    "            float(sequence_data['attempt_count'].mean()) if 'attempt_count' in sequence_data.columns else 1.0,\n",
    "            float((sequence_data['answer_given'] == True).sum()) if 'answer_given' in sequence_data.columns else 0.0,\n",
    "        ]\n",
    "        \n",
    "        sequence_student_features.append(features)\n",
    "    \n",
    "    sequence_student_features = torch.tensor(sequence_student_features, dtype=torch.float32, device=device)\n",
    "    print(f\"Sequence-based student features: {sequence_student_features.shape} on {device}\")\n",
    "    \n",
    "    # === PROBLEM FEATURES (Static but Enhanced) ===\n",
    "    problem_features_list = []\n",
    "    \n",
    "    # Encode categorical features\n",
    "    le_content = LabelEncoder()\n",
    "    le_problem_type = LabelEncoder()\n",
    "    df_copy = df.copy()\n",
    "    df_copy['content_source_encoded'] = le_content.fit_transform(df_copy['content_source'].fillna('Unknown'))\n",
    "    df_copy['problem_type_encoded'] = le_problem_type.fit_transform(df_copy['problem_type'].fillna('Unknown'))\n",
    "    \n",
    "    for problem_id in problem_to_idx.keys():\n",
    "        problem_data = df_copy[df_copy['problem_id'] == problem_id].iloc[0]\n",
    "        \n",
    "        # Get skills for this problem\n",
    "        problem_skills = []\n",
    "        if pd.notna(problem_data['skills']):\n",
    "            problem_skills = [s.strip() for s in str(problem_data['skills']).split(',')]\n",
    "        \n",
    "        features = [\n",
    "            # Basic problem statistics\n",
    "            float(problem_data['student_answer_count']) if pd.notna(problem_data['student_answer_count']) else 0.0,\n",
    "            float(problem_data['mean_correct']) if pd.notna(problem_data['mean_correct']) else 0.5,\n",
    "            float(problem_data['mean_time_on_task']) if pd.notna(problem_data['mean_time_on_task']) else 100.0,\n",
    "            \n",
    "            # Problem complexity indicators\n",
    "            float(len(problem_skills)),  # Number of skills required\n",
    "            \n",
    "            # Encoded categorical features\n",
    "            float(problem_data['content_source_encoded']),\n",
    "            float(problem_data['problem_type_encoded']),\n",
    "        ]\n",
    "        \n",
    "        problem_features_list.append(features)\n",
    "    \n",
    "    problem_features = torch.tensor(problem_features_list, dtype=torch.float32, device=device)\n",
    "    print(f\"Problem features: {problem_features.shape} on {device}\")\n",
    "    \n",
    "    # === SKILL FEATURES (Enhanced with Temporal Context) ===\n",
    "    skill_features_list = []\n",
    "    \n",
    "    # Pre-calculate skill statistics from sequences\n",
    "    skill_stats = defaultdict(lambda: {'attempts': [], 'times': [], 'sequence_contexts': []})\n",
    "    \n",
    "    for seq in sequences:\n",
    "        for _, row in seq['sequence_data'].iterrows():\n",
    "            if pd.notna(row['skills']):\n",
    "                problem_skills = [s.strip() for s in str(row['skills']).split(',')]\n",
    "                for skill in problem_skills:\n",
    "                    if skill in skill_to_idx:\n",
    "                        skill_stats[skill]['attempts'].append(row['correct'])\n",
    "                        skill_stats[skill]['times'].append(row['time_on_task'])\n",
    "                        skill_stats[skill]['sequence_contexts'].append(seq['sequence_length'])\n",
    "    \n",
    "    for skill in skill_to_idx.keys():\n",
    "        if skill in skill_stats:\n",
    "            attempts = skill_stats[skill]['attempts']\n",
    "            times = skill_stats[skill]['times']\n",
    "            contexts = skill_stats[skill]['sequence_contexts']\n",
    "            \n",
    "            features = [\n",
    "                float(len(attempts)),  # Frequency across all sequences\n",
    "                float(np.mean(attempts)) if attempts else 0.5,  # Average correctness\n",
    "                float(np.mean(times)) if times else 100.0,  # Average time\n",
    "                float(np.std(attempts)) if len(attempts) > 1 else 0.5,  # Performance variability\n",
    "                float(np.mean(contexts)) if contexts else 5.0,  # Average sequence context length\n",
    "            ]\n",
    "        else:\n",
    "            # Default features for skills not seen in sequences\n",
    "            features = [0.0, 0.5, 100.0, 0.5, 5.0]\n",
    "        \n",
    "        skill_features_list.append(features)\n",
    "    \n",
    "    skill_features = torch.tensor(skill_features_list, dtype=torch.float32, device=device)\n",
    "    print(f\"Skill features: {skill_features.shape} on {device}\")\n",
    "    \n",
    "    return sequence_student_features, problem_features, skill_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0089588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_edges(sequences, df, student_to_idx, problem_to_idx, skill_to_idx, device='cuda'):\n",
    "    \"\"\"\n",
    "    Create edges that capture temporal learning patterns and relationships\n",
    "    \"\"\"\n",
    "    print(\"=== CREATING TEMPORAL EDGES ===\")\n",
    "    \n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # === SEQUENCE-PROBLEM EDGES (Main Prediction Edges) ===\n",
    "    sequence_problem_edges = []\n",
    "    sequence_problem_edge_features = []\n",
    "    \n",
    "    for seq_idx, seq in enumerate(sequences):\n",
    "        target_problem_id = seq['prediction_problem_id']\n",
    "        \n",
    "        if target_problem_id in problem_to_idx:\n",
    "            target_problem_idx = problem_to_idx[target_problem_id]\n",
    "            sequence_data = seq['sequence_data']\n",
    "            \n",
    "            # Edge from sequence to target problem\n",
    "            sequence_problem_edges.append([seq_idx, target_problem_idx])\n",
    "            \n",
    "            # Rich edge features capturing learning context\n",
    "            target_problem_data = df[df['problem_id'] == target_problem_id].iloc[0]\n",
    "            \n",
    "            # Historical performance context\n",
    "            historical_performance = float(sequence_data['correct'].mean())\n",
    "            recent_performance = float(sequence_data['correct'].tail(3).mean()) if len(sequence_data) >= 3 else historical_performance\n",
    "            \n",
    "            # Skill overlap analysis\n",
    "            seq_skills = set()\n",
    "            for skills_str in sequence_data['skills'].dropna():\n",
    "                if isinstance(skills_str, str):\n",
    "                    seq_skills.update([s.strip() for s in skills_str.split(',')])\n",
    "            \n",
    "            target_skills = set()\n",
    "            if pd.notna(target_problem_data['skills']):\n",
    "                target_skills.update([s.strip() for s in str(target_problem_data['skills']).split(',')])\n",
    "            \n",
    "            skill_overlap = len(seq_skills.intersection(target_skills))\n",
    "            total_skills = len(seq_skills.union(target_skills))\n",
    "            skill_overlap_ratio = float(skill_overlap / total_skills) if total_skills > 0 else 0.0\n",
    "            \n",
    "            # Content source familiarity\n",
    "            seq_sources = set(sequence_data['content_source'].dropna())\n",
    "            target_source = target_problem_data['content_source']\n",
    "            source_familiarity = float(1.0 if target_source in seq_sources else 0.0)\n",
    "            \n",
    "            # Time-based features\n",
    "            avg_time_in_seq = float(sequence_data['time_on_task'].mean())\n",
    "            avg_hints_in_seq = float(sequence_data['fraction_of_hints_used'].mean())\n",
    "            \n",
    "            # Learning trajectory features\n",
    "            if len(sequence_data) > 1:\n",
    "                performance_trend = float(sequence_data['correct'].diff().tail(3).mean())\n",
    "            else:\n",
    "                performance_trend = 0.0\n",
    "            \n",
    "            edge_features = [\n",
    "                historical_performance,\n",
    "                recent_performance,\n",
    "                skill_overlap_ratio,\n",
    "                float(skill_overlap),\n",
    "                source_familiarity,\n",
    "                avg_time_in_seq,\n",
    "                avg_hints_in_seq,\n",
    "                performance_trend,\n",
    "                float(seq['sequence_length']),\n",
    "            ]\n",
    "            \n",
    "            sequence_problem_edge_features.append(edge_features)\n",
    "    \n",
    "    sequence_problem_edges = torch.tensor(sequence_problem_edges, dtype=torch.long, device=device).T\n",
    "    sequence_problem_edge_features = torch.tensor(sequence_problem_edge_features, dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(f\"Sequence-Problem edges: {sequence_problem_edges.shape} on {device}\")\n",
    "    print(f\"Sequence-Problem edge features: {sequence_problem_edge_features.shape} on {device}\")\n",
    "    \n",
    "    # === PROBLEM-SKILL EDGES ===\n",
    "    problem_skill_pairs = []\n",
    "    for problem_id in problem_to_idx.keys():\n",
    "        problem_data = df[df['problem_id'] == problem_id].iloc[0]\n",
    "        if pd.notna(problem_data['skills']):\n",
    "            problem_idx = problem_to_idx[problem_id]\n",
    "            skills_list = [s.strip() for s in str(problem_data['skills']).split(',')]\n",
    "            \n",
    "            for skill in skills_list:\n",
    "                if skill in skill_to_idx:\n",
    "                    skill_idx = skill_to_idx[skill]\n",
    "                    problem_skill_pairs.append([problem_idx, skill_idx])\n",
    "    \n",
    "    # Remove duplicates and convert to tensor\n",
    "    problem_skill_edges = torch.tensor(\n",
    "        list(set(map(tuple, problem_skill_pairs))), \n",
    "        dtype=torch.long, device=device\n",
    "    ).T if problem_skill_pairs else torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "    \n",
    "    print(f\"Problem-Skill edges: {problem_skill_edges.shape} on {device}\")\n",
    "    \n",
    "    return sequence_problem_edges, sequence_problem_edge_features, problem_skill_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09d191e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_heterogeneous_graph(sequence_features, problem_features, skill_features,\n",
    "                                     seq_prob_edges, seq_prob_edge_features, prob_skill_edges, \n",
    "                                     device='cuda'):\n",
    "    \"\"\"\n",
    "    Build the complete temporal heterogeneous graph for TEG-NeSyNet\n",
    "    \"\"\"\n",
    "    print(\"=== BUILDING TEMPORAL HETEROGENEOUS GRAPH ===\")\n",
    "    \n",
    "    # Initialize heterogeneous graph\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Add node features\n",
    "    data['sequence'].x = sequence_features  # Dynamic student states based on sequences\n",
    "    data['problem'].x = problem_features    # Static problem characteristics\n",
    "    data['skill'].x = skill_features        # Skill difficulty and context features\n",
    "    \n",
    "    # Add main prediction edges (sequence -> problem)\n",
    "    data['sequence', 'predicts', 'problem'].edge_index = seq_prob_edges\n",
    "    data['sequence', 'predicts', 'problem'].edge_attr = seq_prob_edge_features\n",
    "    \n",
    "    # Add problem-skill requirement edges\n",
    "    if prob_skill_edges.size(1) > 0:\n",
    "        data['problem', 'requires', 'skill'].edge_index = prob_skill_edges\n",
    "    \n",
    "    # Add reverse edges for better message passing\n",
    "    data['problem', 'predicted_by', 'sequence'].edge_index = seq_prob_edges.flip(0)\n",
    "    \n",
    "    if prob_skill_edges.size(1) > 0:\n",
    "        data['skill', 'required_by', 'problem'].edge_index = prob_skill_edges.flip(0)\n",
    "    \n",
    "    # Device handling for display\n",
    "    device_name = str(device).upper()\n",
    "    print(f\"Temporal graph created on {device_name}:\")\n",
    "    print(f\"- Sequence nodes (dynamic student states): {data['sequence'].x.shape}\")\n",
    "    print(f\"- Problem nodes: {data['problem'].x.shape}\")\n",
    "    print(f\"- Skill nodes: {data['skill'].x.shape}\")\n",
    "    print(f\"- Prediction edges: {data['sequence', 'predicts', 'problem'].edge_index.shape[1]}\")\n",
    "    if 'problem' in data and 'requires' in data[('problem', 'requires', 'skill')]:\n",
    "        print(f\"- Requirement edges: {data['problem', 'requires', 'skill'].edge_index.shape[1]}\")\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7b20cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_standard_scaling_pytorch_only_fixed(graph_data, device='cuda'):\n",
    "    \"\"\"\n",
    "    Apply standard scaling with NaN handling\n",
    "    \"\"\"\n",
    "    print(\"=== APPLYING STANDARD SCALING (FIXED) ===\")\n",
    "    \n",
    "    scalers = {}\n",
    "    \n",
    "    # Scale sequence features with NaN handling\n",
    "    seq_features = graph_data['sequence'].x\n",
    "    # Replace any NaN/Inf with zeros first\n",
    "    seq_features = torch.nan_to_num(seq_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    seq_mean = seq_features.mean(dim=0, keepdim=True)\n",
    "    seq_std = seq_features.std(dim=0, keepdim=True)\n",
    "    seq_std = torch.where(seq_std < 1e-6, torch.ones_like(seq_std), seq_std)  # Avoid near-zero std\n",
    "    graph_data['sequence'].x = (seq_features - seq_mean) / seq_std\n",
    "    scalers['sequence'] = {'mean': seq_mean, 'std': seq_std}\n",
    "    \n",
    "    # Scale problem features\n",
    "    prob_features = graph_data['problem'].x\n",
    "    prob_features = torch.nan_to_num(prob_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    prob_mean = prob_features.mean(dim=0, keepdim=True)\n",
    "    prob_std = prob_features.std(dim=0, keepdim=True)\n",
    "    prob_std = torch.where(prob_std < 1e-6, torch.ones_like(prob_std), prob_std)\n",
    "    graph_data['problem'].x = (prob_features - prob_mean) / prob_std\n",
    "    scalers['problem'] = {'mean': prob_mean, 'std': prob_std}\n",
    "    \n",
    "    # Scale skill features\n",
    "    skill_features = graph_data['skill'].x\n",
    "    skill_features = torch.nan_to_num(skill_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    skill_mean = skill_features.mean(dim=0, keepdim=True)\n",
    "    skill_std = skill_features.std(dim=0, keepdim=True)\n",
    "    skill_std = torch.where(skill_std < 1e-6, torch.ones_like(skill_std), skill_std)\n",
    "    graph_data['skill'].x = (skill_features - skill_mean) / skill_std\n",
    "    scalers['skill'] = {'mean': skill_mean, 'std': skill_std}\n",
    "    \n",
    "    # Scale edge features\n",
    "    edge_features = graph_data['sequence', 'predicts', 'problem'].edge_attr\n",
    "    edge_features = torch.nan_to_num(edge_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    edge_mean = edge_features.mean(dim=0, keepdim=True)\n",
    "    edge_std = edge_features.std(dim=0, keepdim=True)\n",
    "    edge_std = torch.where(edge_std < 1e-6, torch.ones_like(edge_std), edge_std)\n",
    "    graph_data['sequence', 'predicts', 'problem'].edge_attr = (edge_features - edge_mean) / edge_std\n",
    "    scalers['edge'] = {'mean': edge_mean, 'std': edge_std}\n",
    "    \n",
    "    print(f\"âœ… All features standardized and NaN-cleaned\")\n",
    "    print(f\"Sequence features: meanâ‰ˆ{graph_data['sequence'].x.mean().item():.3f}, stdâ‰ˆ{graph_data['sequence'].x.std().item():.3f}\")\n",
    "    \n",
    "    return graph_data, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "908ef309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_temporal_encoding_pytorch_only_fixed(graph_data, sequences, device='cuda'):\n",
    "    \"\"\"\n",
    "    Add temporal encoding with robust NaN handling\n",
    "    \"\"\"\n",
    "    print(\"=== ENHANCING TEMPORAL ENCODING (FIXED) ===\")\n",
    "    \n",
    "    enhanced_sequence_features = []\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        sequence_data = seq['sequence_data']\n",
    "        current_features = graph_data['sequence'].x[i]\n",
    "        \n",
    "        # Robust feature calculation with NaN handling\n",
    "        try:\n",
    "            seq_len = float(len(sequence_data))\n",
    "            success_rate = float(sequence_data['correct'].sum() / len(sequence_data))\n",
    "            \n",
    "            # Handle potential NaN\n",
    "            if pd.isna(success_rate):\n",
    "                success_rate = 0.0\n",
    "                \n",
    "        except:\n",
    "            seq_len = 5.0  # Default\n",
    "            success_rate = 0.0\n",
    "        \n",
    "        seq_len_feature = torch.tensor([seq_len], dtype=torch.float32, device=device)\n",
    "        success_rate_feature = torch.tensor([success_rate], dtype=torch.float32, device=device)\n",
    "        \n",
    "        enhanced_features = torch.cat([current_features, seq_len_feature, success_rate_feature])\n",
    "        enhanced_sequence_features.append(enhanced_features)\n",
    "    \n",
    "    enhanced_features_tensor = torch.stack(enhanced_sequence_features)\n",
    "    # Clean any remaining NaN\n",
    "    enhanced_features_tensor = torch.nan_to_num(enhanced_features_tensor, nan=0.0)\n",
    "    graph_data['sequence'].x = enhanced_features_tensor\n",
    "    \n",
    "    print(f\"âœ… Enhanced temporal features: {enhanced_features_tensor.shape}\")\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b11c8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_features_pytorch_only(graph_data):\n",
    "    \"\"\"\n",
    "    Validate feature quality using pure PyTorch\n",
    "    \"\"\"\n",
    "    print(\"=== FEATURE VALIDATION (PYTORCH ONLY) ===\")\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check for NaN/Inf values\n",
    "    for node_type in graph_data.node_types:\n",
    "        features = graph_data[node_type].x\n",
    "        if torch.isnan(features).any():\n",
    "            issues.append(f\"NaN values in {node_type} features\")\n",
    "        if torch.isinf(features).any():\n",
    "            issues.append(f\"Inf values in {node_type} features\")\n",
    "    \n",
    "    # Check edge features\n",
    "    for edge_type in graph_data.edge_types:\n",
    "        if hasattr(graph_data[edge_type], 'edge_attr'):\n",
    "            edge_features = graph_data[edge_type].edge_attr\n",
    "            if torch.isnan(edge_features).any():\n",
    "                issues.append(f\"NaN values in {edge_type} edge features\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"âš ï¸  Issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"   - {issue}\")\n",
    "    else:\n",
    "        print(\"âœ… All features validated successfully\")\n",
    "    \n",
    "    return len(issues) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dfc9e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complete_temporal_teg_nesynet_fixed(df, base_sequence_length=5, max_sequences_per_student=3, device='cuda'):\n",
    "    \"\"\"Fixed version with robust NaN handling\"\"\"\n",
    "    print(\"=== BUILDING FIXED TEMPORAL TEG-NESYNET ===\")\n",
    "    \n",
    "    # Steps 1-6: Same as before\n",
    "    unique_skills = analyze_graph_structure(df)\n",
    "    student_to_idx, problem_to_idx, skill_to_idx = create_node_mappings(df, unique_skills)\n",
    "    sequences = create_adaptive_temporal_sequences(df, base_sequence_length, max_sequences_per_student, device)\n",
    "    sequence_features, problem_features, skill_features = extract_temporal_node_features(\n",
    "        sequences, df, student_to_idx, problem_to_idx, skill_to_idx, device\n",
    "    )\n",
    "    seq_prob_edges, seq_prob_edge_features, prob_skill_edges = create_temporal_edges(\n",
    "        sequences, df, student_to_idx, problem_to_idx, skill_to_idx, device\n",
    "    )\n",
    "    \n",
    "    graph_data = build_temporal_heterogeneous_graph(\n",
    "        sequence_features, problem_features, skill_features,\n",
    "        seq_prob_edges, seq_prob_edge_features, prob_skill_edges, device\n",
    "    )\n",
    "    \n",
    "    # Fixed feature processing\n",
    "    print(\"\\n=== FEATURE PROCESSING (FIXED) ===\")\n",
    "    graph_data, scalers = apply_standard_scaling_pytorch_only_fixed(graph_data, device)\n",
    "    graph_data = enhance_temporal_encoding_pytorch_only_fixed(graph_data, sequences, device)\n",
    "    graph_data, final_scalers = apply_standard_scaling_pytorch_only_fixed(graph_data, device)\n",
    "    is_valid = validate_features_pytorch_only(graph_data)\n",
    "    \n",
    "    # Extract targets\n",
    "    targets = torch.tensor([seq['target'] for seq in sequences], dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(f\"\\n=== COMPLETION ===\")\n",
    "    print(f\"Feature processing valid: {is_valid}\")\n",
    "    \n",
    "    return {\n",
    "        'graph_data': graph_data,\n",
    "        'targets': targets,\n",
    "        'sequences': sequences,\n",
    "        'scalers': final_scalers,\n",
    "        'mappings': {\n",
    "            'student_to_idx': student_to_idx,\n",
    "            'problem_to_idx': problem_to_idx,\n",
    "            'skill_to_idx': skill_to_idx\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce442863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fixed pipeline...\n",
      "=== BUILDING FIXED TEMPORAL TEG-NESYNET ===\n",
      "=== GRAPH STRUCTURE ANALYSIS ===\n",
      "Total rows: 110474\n",
      "Unique students: 10000\n",
      "Unique problems: 21777\n",
      "Unique skills: 762\n",
      "\n",
      "Student attempt distribution:\n",
      "Min attempts: 5\n",
      "Max attempts: 20\n",
      "Mean attempts: 11.05\n",
      "Median attempts: 10.00\n",
      "=== NODE MAPPINGS CREATED ===\n",
      "Students: 10000 mappings\n",
      "Problems: 21777 mappings\n",
      "Skills: 762 mappings\n",
      "=== CREATING ADAPTIVE TEMPORAL SEQUENCES ===\n",
      "\n",
      "=== SEQUENCE CREATION SUMMARY ===\n",
      "Total students: 10000\n",
      "Students with sequences: 8808\n",
      "Total sequences created: 23820\n",
      "Average sequences per valid student: 2.70\n",
      "Sequence length range: 5-19\n",
      "=== EXTRACTING TEMPORAL NODE FEATURES ===\n",
      "Sequence-based student features: torch.Size([23820, 12]) on cuda\n",
      "Problem features: torch.Size([21777, 6]) on cuda\n",
      "Skill features: torch.Size([762, 5]) on cuda\n",
      "=== CREATING TEMPORAL EDGES ===\n",
      "Sequence-Problem edges: torch.Size([2, 23820]) on cuda\n",
      "Sequence-Problem edge features: torch.Size([23820, 9]) on cuda\n",
      "Problem-Skill edges: torch.Size([2, 14283]) on cuda\n",
      "=== BUILDING TEMPORAL HETEROGENEOUS GRAPH ===\n",
      "Temporal graph created on CUDA:\n",
      "- Sequence nodes (dynamic student states): torch.Size([23820, 12])\n",
      "- Problem nodes: torch.Size([21777, 6])\n",
      "- Skill nodes: torch.Size([762, 5])\n",
      "- Prediction edges: 23820\n",
      "\n",
      "=== FEATURE PROCESSING (FIXED) ===\n",
      "=== APPLYING STANDARD SCALING (FIXED) ===\n",
      "âœ… All features standardized and NaN-cleaned\n",
      "Sequence features: meanâ‰ˆ-0.000, stdâ‰ˆ1.000\n",
      "=== ENHANCING TEMPORAL ENCODING (FIXED) ===\n",
      "âœ… Enhanced temporal features: torch.Size([23820, 14])\n",
      "=== APPLYING STANDARD SCALING (FIXED) ===\n",
      "âœ… All features standardized and NaN-cleaned\n",
      "Sequence features: meanâ‰ˆ0.000, stdâ‰ˆ1.000\n",
      "=== FEATURE VALIDATION (PYTORCH ONLY) ===\n",
      "âœ… All features validated successfully\n",
      "\n",
      "=== COMPLETION ===\n",
      "Feature processing valid: True\n",
      "âœ… Model saved successfully!\n",
      "Model file: ./teg_nesynet_models\\teg_nesynet_temporal_v1.pt\n",
      "Metadata file: ./teg_nesynet_models\\teg_nesynet_temporal_v1_metadata.txt\n",
      "Model size: 67.23 MB\n",
      "\n",
      "ðŸŽ‰ TEG-NeSyNet model ready for GNN training!\n",
      "Training samples: 23820\n",
      "Graph nodes: 46359\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_teg_nesynet_model(result, save_dir=\"./models\", model_name=None):\n",
    "    \"\"\"\n",
    "    Save the complete TEG-NeSyNet model with metadata\n",
    "    \"\"\"\n",
    "    # Create save directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate model name with timestamp if not provided\n",
    "    if model_name is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_name = f\"teg_nesynet_{timestamp}\"\n",
    "    \n",
    "    # Prepare save data\n",
    "    save_data = {\n",
    "        # Core model components\n",
    "        'graph_data': result['graph_data'],\n",
    "        'targets': result['targets'],\n",
    "        'sequences': result['sequences'],\n",
    "        'scalers': result['scalers'],\n",
    "        'mappings': result['mappings'],\n",
    "        \n",
    "        # Model metadata\n",
    "        'metadata': {\n",
    "            'model_name': model_name,\n",
    "            'save_timestamp': datetime.now().isoformat(),\n",
    "            'total_sequences': len(result['sequences']),\n",
    "            'num_students': len(result['mappings']['student_to_idx']),\n",
    "            'num_problems': len(result['mappings']['problem_to_idx']),\n",
    "            'num_skills': len(result['mappings']['skill_to_idx']),\n",
    "            'device': str(result['graph_data']['sequence'].x.device),\n",
    "            'node_types': list(result['graph_data'].node_types),\n",
    "            'edge_types': list(result['graph_data'].edge_types),\n",
    "            'feature_shapes': {\n",
    "                'sequence_features': list(result['graph_data']['sequence'].x.shape),\n",
    "                'problem_features': list(result['graph_data']['problem'].x.shape),\n",
    "                'skill_features': list(result['graph_data']['skill'].x.shape)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save paths\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}.pt\")\n",
    "    metadata_path = os.path.join(save_dir, f\"{model_name}_metadata.txt\")\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(save_data, model_path)\n",
    "    \n",
    "    # Save human-readable metadata\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        f.write(\"TEG-NeSyNet Model Metadata\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for key, value in save_data['metadata'].items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"âœ… Model saved successfully!\")\n",
    "    print(f\"Model file: {model_path}\")\n",
    "    print(f\"Metadata file: {metadata_path}\")\n",
    "    print(f\"Model size: {os.path.getsize(model_path) / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    return model_path, metadata_path\n",
    "\n",
    "# Run the fixed pipeline and save\n",
    "print(\"Running fixed pipeline...\")\n",
    "result_fixed = build_complete_temporal_teg_nesynet_fixed(\n",
    "    train, \n",
    "    base_sequence_length=5, \n",
    "    max_sequences_per_student=3, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model_path, metadata_path = save_teg_nesynet_model(\n",
    "    result_fixed, \n",
    "    save_dir=\"./teg_nesynet_models\", \n",
    "    model_name=\"teg_nesynet_temporal_v1\"\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ TEG-NeSyNet model ready for GNN training!\")\n",
    "print(f\"Training samples: {len(result_fixed['sequences'])}\")\n",
    "print(f\"Graph nodes: {result_fixed['graph_data']['sequence'].x.shape[0] + result_fixed['graph_data']['problem'].x.shape[0] + result_fixed['graph_data']['skill'].x.shape[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
